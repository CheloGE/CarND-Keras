{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook aims to create a basic model to train a small dataset of traffic signs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Flatten\n",
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** dataset shape ******\n",
      "training dataset: (100, 32, 32, 3)\n",
      "training labels: (100,)\n",
      "testing dataset: (20, 32, 32, 3)\n",
      "testing labels: (20,)\n"
     ]
    }
   ],
   "source": [
    "train_loc = \"./Datasets/small_train_traffic.p\"\n",
    "test_loc = \"./Datasets/small_test_traffic.p\"\n",
    "X_train=pd.read_pickle(train_loc)['features']\n",
    "Y_train=pd.read_pickle(train_loc)['labels']\n",
    "X_test=pd.read_pickle(test_loc)['features']\n",
    "Y_test=pd.read_pickle(test_loc)['labels']\n",
    "print(\"****** dataset shape ******\")\n",
    "print(f\"training dataset: {X_train.shape}\")\n",
    "print(f\"training labels: {Y_train.shape}\")\n",
    "print(f\"testing dataset: {X_test.shape}\")\n",
    "print(f\"testing labels: {Y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** new dataset shape ******\n",
      "training dataset: (100, 32, 32, 3)\n",
      "training labels: (100, 5)\n",
      "testing dataset: (20, 32, 32, 3)\n",
      "testing labels: (20, 5)\n"
     ]
    }
   ],
   "source": [
    "# Normalize images\n",
    "X_train_norm = np.array(X_train / 255.0 - 0.5 )\n",
    "X_test_norm = np.array(X_test / 255.0 - 0.5 )\n",
    "# One hot encode labels\n",
    "oneHot = LabelBinarizer()\n",
    "# calculates oneHot parameters based on the ordinal classes\n",
    "oneHot.fit(Y_train)\n",
    "# Apply the one hot encoding parameters to the labels\n",
    "Y_train_oneHot = oneHot.transform(Y_train)\n",
    "Y_test_oneHot = oneHot.transform(Y_test)\n",
    "print(\"****** new dataset shape ******\")\n",
    "print(f\"training dataset: {X_train_norm.shape}\")\n",
    "print(f\"training labels: {Y_train_oneHot.shape}\")\n",
    "print(f\"testing dataset: {X_test_norm.shape}\")\n",
    "print(f\"testing labels: {Y_test_oneHot.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_model = Sequential()\n",
    "simple_model.add(Flatten(input_shape=(32,32,3)))\n",
    "simple_model.add(Dense(128))\n",
    "simple_model.add(Activation(\"relu\"))\n",
    "simple_model.add(Dense(5))\n",
    "simple_model.add(Activation(\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_2 (Flatten)          (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               393344    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 645       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 393,989\n",
      "Trainable params: 393,989\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Model summary\n",
    "simple_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define optimizer\n",
    "simple_model.compile(\"adam\", \"categorical_crossentropy\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80 samples, validate on 20 samples\n",
      "Epoch 1/3\n",
      "80/80 [==============================] - 0s 5ms/step - loss: 1.3534 - acc: 0.2875 - val_loss: 0.8214 - val_acc: 0.6000\n",
      "Epoch 2/3\n",
      "80/80 [==============================] - 0s 337us/step - loss: 0.9665 - acc: 0.5875 - val_loss: 0.5655 - val_acc: 0.7000\n",
      "Epoch 3/3\n",
      "80/80 [==============================] - 0s 325us/step - loss: 0.7096 - acc: 0.6875 - val_loss: 0.5342 - val_acc: 0.8500\n"
     ]
    }
   ],
   "source": [
    "#train network\n",
    "history = simple_model.fit(X_train_norm, Y_train_oneHot, epochs=3, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 32,\n",
       " 'epochs': 3,\n",
       " 'steps': None,\n",
       " 'samples': 80,\n",
       " 'verbose': 1,\n",
       " 'do_validation': True,\n",
       " 'metrics': ['loss', 'acc', 'val_loss', 'val_acc']}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The returned \"history\" object holds a record of the loss values and metric values during training\n",
    "history.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "20/20 [==============================] - 0s 100us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8018772006034851, 0.6499999761581421]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test model\n",
    "results = simple_model.evaluate(X_test_norm, Y_test_oneHot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'acc']\n",
      "[0.8018772006034851, 0.6499999761581421]\n",
      "Test results- loss: 0.8018772006034851, acc: 0.6499999761581421\n"
     ]
    }
   ],
   "source": [
    "# `results` holds the results for the model metrics parameters set at the beginning\n",
    "print(simple_model.metrics_names)\n",
    "print(results)\n",
    "print(f\"Test results- {simple_model.metrics_names[0]}: {results[0]}, {simple_model.metrics_names[1]}: {results[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
