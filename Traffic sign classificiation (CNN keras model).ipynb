{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook aims to create a CNN model to train a small dataset of traffic signs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Flatten, Dense, Activation, Dropout\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.optimizers import adam\n",
    "from keras.layers.pooling import MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** shape of current data ****\n",
      "Training features: (100, 32, 32, 3)\n",
      "Training labels: (100,)\n",
      "testing features: (20, 32, 32, 3)\n",
      "testing labels: (20,)\n"
     ]
    }
   ],
   "source": [
    "train_folder = \"./Datasets/small_train_traffic.p\"\n",
    "test_folder = \"./Datasets/small_test_traffic.p\"\n",
    "X_train = pd.read_pickle(train_folder)['features']\n",
    "Y_train = pd.read_pickle(train_folder)['labels']\n",
    "X_test = pd.read_pickle(test_folder)['features']\n",
    "Y_test = pd.read_pickle(test_folder)['labels']\n",
    "print(\"**** shape of current data ****\")\n",
    "print(f\"Training features: {X_train.shape}\")\n",
    "print(f\"Training labels: {Y_train.shape}\")\n",
    "print(f\"testing features: {X_test.shape}\")\n",
    "print(f\"testing labels: {Y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** new dataset shape ******\n",
      "training dataset: (100, 32, 32, 3)\n",
      "testing dataset: (20, 32, 32, 3)\n",
      "training labels: (100, 5)\n",
      "testing labels: (20, 5)\n"
     ]
    }
   ],
   "source": [
    "# Normalize features\n",
    "X_train_norm = (X_train -127.5)/255\n",
    "X_test_norm = (X_test -127.5)/255\n",
    "## One hot encode labels\n",
    "oneHot = LabelBinarizer()\n",
    "# get parameters of one hot encoding based on the classes\n",
    "oneHot.fit(Y_train)\n",
    "# transform data using the one hot encoding parameters\n",
    "Y_train_oneHot = oneHot.transform(Y_train)\n",
    "Y_test_oneHot = oneHot.transform(Y_test)\n",
    "print(\"****** new dataset shape ******\")\n",
    "print(f\"training dataset: {X_train_norm.shape}\")\n",
    "print(f\"testing dataset: {X_test_norm.shape}\")\n",
    "print(f\"training labels: {Y_train_oneHot.shape}\")\n",
    "print(f\"testing labels: {Y_test_oneHot.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = Sequential()\n",
    "my_model.add(Conv2D(12, 3, input_shape=(32,32,3)))\n",
    "my_model.add(Activation(\"relu\"))\n",
    "my_model.add(Conv2D(6, 5))\n",
    "my_model.add(Activation(\"relu\"))\n",
    "my_model.add(Flatten())\n",
    "my_model.add(Activation(\"relu\"))\n",
    "my_model.add(Dense(60))\n",
    "my_model.add(Activation(\"relu\"))\n",
    "my_model.add(Dense(5))\n",
    "my_model.add(Activation(\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 30, 30, 12)        336       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 30, 30, 12)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 26, 26, 6)         1806      \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 26, 26, 6)         0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 4056)              0         \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 4056)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 60)                243420    \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 60)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 5)                 305       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 245,867\n",
      "Trainable params: 245,867\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "my_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set optimizer\n",
    "my_model.compile(adam(lr=0.0001), \"categorical_crossentropy\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80 samples, validate on 20 samples\n",
      "Epoch 1/10\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.0559 - acc: 0.8375 - val_loss: 1.1423 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.0386 - acc: 0.6875 - val_loss: 1.1316 - val_acc: 0.7000\n",
      "Epoch 3/10\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 1.0138 - acc: 0.6375 - val_loss: 1.0898 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.9629 - acc: 0.8000 - val_loss: 1.0618 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.9429 - acc: 0.8500 - val_loss: 1.0274 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.9061 - acc: 0.8375 - val_loss: 0.9736 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.8647 - acc: 0.8375 - val_loss: 0.9334 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.8253 - acc: 0.8375 - val_loss: 0.8947 - val_acc: 0.7500\n",
      "Epoch 9/10\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.7988 - acc: 0.7750 - val_loss: 0.8602 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.7619 - acc: 0.8500 - val_loss: 0.8168 - val_acc: 0.8000\n"
     ]
    }
   ],
   "source": [
    "history = my_model.fit(X_train_norm, Y_train_oneHot, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "20/20 [==============================] - 0s 500us/step\n"
     ]
    }
   ],
   "source": [
    "# test data\n",
    "result=my_model.evaluate(X_test_norm, Y_test_oneHot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'acc']\n",
      "[0.8452666997909546, 0.8500000238418579]\n",
      "Test results- loss: 0.8452666997909546, acc: 0.8500000238418579\n"
     ]
    }
   ],
   "source": [
    "# `results` holds the results for the model metrics parameters set at the beginning\n",
    "print(my_model.metrics_names)\n",
    "print(result)\n",
    "print(f\"Test results- {my_model.metrics_names[0]}: {result[0]}, {my_model.metrics_names[1]}: {result[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lets try a different architecture including some regularization (dropout) and pooling layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Convolutional Pooling Neural Network with Dropout in Keras Here\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(32, 32, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(5))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8 (Conv2D)            (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 7200)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 128)               921728    \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 5)                 645       \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 923,269\n",
      "Trainable params: 923,269\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80 samples, validate on 20 samples\n",
      "Epoch 1/10\n",
      "80/80 [==============================] - 1s 11ms/step - loss: 1.2297 - acc: 0.3875 - val_loss: 0.7367 - val_acc: 0.7000\n",
      "Epoch 2/10\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.7532 - acc: 0.5750 - val_loss: 0.4464 - val_acc: 1.0000\n",
      "Epoch 3/10\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.5082 - acc: 0.8250 - val_loss: 0.3086 - val_acc: 1.0000\n",
      "Epoch 4/10\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.3831 - acc: 0.8375 - val_loss: 0.2251 - val_acc: 0.9500\n",
      "Epoch 5/10\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.3118 - acc: 0.8875 - val_loss: 0.1764 - val_acc: 1.0000\n",
      "Epoch 6/10\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.2453 - acc: 0.9250 - val_loss: 0.1488 - val_acc: 1.0000\n",
      "Epoch 7/10\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.2217 - acc: 0.9750 - val_loss: 0.1535 - val_acc: 0.8500\n",
      "Epoch 8/10\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.2165 - acc: 0.8500 - val_loss: 0.1565 - val_acc: 0.8500\n",
      "Epoch 9/10\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.2519 - acc: 0.8125 - val_loss: 0.0929 - val_acc: 1.0000\n",
      "Epoch 10/10\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.1820 - acc: 0.9125 - val_loss: 0.0823 - val_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "model.compile('adam', 'categorical_crossentropy', ['accuracy'])\n",
    "history = model.fit(X_train_norm, Y_train_oneHot, epochs=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 400us/step\n",
      "['loss', 'acc']\n",
      "[0.15130497515201569, 1.0]\n",
      "Test results- loss: 0.15130497515201569, acc: 1.0\n"
     ]
    }
   ],
   "source": [
    "# test data\n",
    "results=model.evaluate(X_test_norm, Y_test_oneHot)\n",
    "# `results` holds the results for the model metrics parameters set at the beginning\n",
    "print(model.metrics_names)\n",
    "print(results)\n",
    "print(f\"Test results- {model.metrics_names[0]}: {results[0]}, {model.metrics_names[1]}: {results[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
